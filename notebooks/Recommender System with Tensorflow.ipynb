{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E-Commerce Recommender System with Tensorflow\n",
    "\n",
    "### Objective\n",
    "\n",
    "In this notebook we will be building a recommender system\n",
    "\n",
    "### Procedure\n",
    "\n",
    "1. Recommender Systems (Overview)\n",
    "2. Matrix Factorization for Recommender Systems\n",
    "    1. Dataset preparation and baseline\n",
    "    2. Matrix factorization\n",
    "    3. Implicit feedback datasets\n",
    "    4. SGD-based matrix factorization\n",
    "    5. Bayesian personalized ranking\n",
    "3. RNN for Recommender Systems\n",
    "    1. Data preparation and baseline\n",
    "    2. RNN rec systems in Tensorflow\n",
    "\n",
    "### Dataset and Problem Description\n",
    "\n",
    "* Dataset: [UCI Online Retail Dataset](http://archive.ics.uci.edu/ml/datasets/online+retail)\n",
    "\n",
    "### Topics Covered\n",
    "\n",
    "* Basics of Recommender Systems\n",
    "* Matrix Factorization for Recommender Systems\n",
    "* Bayesian Personalized Ranking\n",
    "* Advanced Recommender Systems based on Recurrent Neural Nets\n",
    "\n",
    "### We should be able to after this project\n",
    "\n",
    "* Be able to prepare data for training a recommender system\n",
    "* How to build models with Tensorflow\n",
    "* Perform simple evaluation of quality of these models\n",
    "\n",
    "### Theoretical Foundations\n",
    "\n",
    "* Recommender systems are applied to help recommend things customers might like in order to sell more products, and recommendation engines do this task very well and use machine learning techniques.\n",
    "\n",
    "**What is a Recommendation Engine?**\n",
    "\n",
    "A recommendation engine filters data using different algorithms and recommends the most relevant item to a user. A recommendation engine first captures a users behavior, and then based on past behavior recommends products that users would be likely to buy\n",
    "\n",
    "In our eCommerce recommender system, it will be a \"customers that bought X also bought Y\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Recommender Systems\n",
    "\n",
    "* **Recommender System:** The task of a RS is to take in a list of possible items and rank them according to preferences of particular users. This list is referred to as a personalized ranking or a **recommendation**\n",
    "    * Recommendations are often based off of past data, this historical data includes\n",
    "        * Data includes: clicks, visits, transaction history, etc.\n",
    "    * ML uses this historical data to find patterns in the behavior of users and come up with the best recommendations\n",
    "    * Great for companies to sell more products\n",
    "* In this chapter we will be implementing multiple RecSys algorithms with Tensorflow\n",
    "\n",
    "Dataset is using UCI Online Retail dataset\n",
    "\n",
    "* 25900 transactions, with each transaction containing 20 items\n",
    "* Total items in matrix would be 540,000\n",
    "* Transactions were made by 4,300 users\n",
    "\n",
    "Features of dataset\n",
    "\n",
    "* Invoice No\n",
    "* Stock Code\n",
    "* Description\n",
    "* Quantity\n",
    "* UnitPrice\n",
    "* CustomerID\n",
    "* Country\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Matrix Factorization for Recommender Systems\n",
    "\n",
    "In this section we will do the following:\n",
    "\n",
    "1. Define the problem\n",
    "2. Establish a few baselines\n",
    "3. Implement classical Matrix factorization algorithm\n",
    "4. Implement Bayesian Personalized Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2.1 Data Preparation and Baseline\n",
    "\n",
    "Steps\n",
    "\n",
    "1. Read the excel data\n",
    "2. Save the data as a pickle file and load it as a pickle file\n",
    "3. Clean data\n",
    "    1. Column names are in capital letters, so lowercase them\n",
    "    2. Filter out transactions that are \"returns\"\n",
    "    3. Remove transactions from unknown users\n",
    "4. \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "df = pd.read_excel('../data/raw/Online Retail.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading takes time so we will save the dataframe into a picklefile\n",
    "import pickle\n",
    "with open('../data/processed/df_retail.bin', 'wb') as f_out:\n",
    "    pickle.dump(df, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle file is faster to read, we will now use Pickled version\n",
    "with open('../data/processed/df_retail.bin', 'rb') as f_in:\n",
    "    df = pickle.load(f_in)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InvoiceNo</th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Description</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>InvoiceDate</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>536365</td>\n",
       "      <td>85123A</td>\n",
       "      <td>WHITE HANGING HEART T-LIGHT HOLDER</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>2.55</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>536365</td>\n",
       "      <td>71053</td>\n",
       "      <td>WHITE METAL LANTERN</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>536365</td>\n",
       "      <td>84406B</td>\n",
       "      <td>CREAM CUPID HEARTS COAT HANGER</td>\n",
       "      <td>8</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>2.75</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>536365</td>\n",
       "      <td>84029G</td>\n",
       "      <td>KNITTED UNION FLAG HOT WATER BOTTLE</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>536365</td>\n",
       "      <td>84029E</td>\n",
       "      <td>RED WOOLLY HOTTIE WHITE HEART.</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  InvoiceNo StockCode                          Description  Quantity  \\\n",
       "0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
       "1    536365     71053                  WHITE METAL LANTERN         6   \n",
       "2    536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
       "3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
       "4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
       "\n",
       "          InvoiceDate  UnitPrice  CustomerID         Country  \n",
       "0 2010-12-01 08:26:00       2.55     17850.0  United Kingdom  \n",
       "1 2010-12-01 08:26:00       3.39     17850.0  United Kingdom  \n",
       "2 2010-12-01 08:26:00       2.75     17850.0  United Kingdom  \n",
       "3 2010-12-01 08:26:00       3.39     17850.0  United Kingdom  \n",
       "4 2010-12-01 08:26:00       3.39     17850.0  United Kingdom  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some problems with the data so far, here are the following problems\n",
    "\n",
    "* column names are in capital letters, so lowercase them\n",
    "* some transactions are returns, not of interest to us\n",
    "* some transaction belong to unknown users\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.lower() # make lowercase\n",
    "# remove transactions that are REturns\n",
    "df = df[~df.invoiceno.astype('str').str.startswith('C')].reset_index(drop=True)\n",
    "# remove transactions from unknown users, assign -1 to them\n",
    "df.customerid = df.customerid.fillna(-1).astype('int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will encode all item IDs (stockcode) with integers. \n",
    "\n",
    "We will do it by building a mapping from each code to some unique index number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stockcode_values = df.stockcode.astype('str')\n",
    "stockcodes = sorted(set(stockcode_values))\n",
    "stockcodes = {c: i for (i, c) in enumerate(stockcodes)}\n",
    "df.stockcode = stockcode_values.map(stockcodes).astype('int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will split the dataset into train, validation and test parts. That means we will have 3 training sets\n",
    "\n",
    "* Training set: before 2011.10.09 (around 10 months of data, approximately 378,500 rows)\n",
    "* Validation set: between 2011.10.09 and 2011.11.09 (one month of data, approximately 64,500 rows)\n",
    "* Test set: after 2011.11.09 (also one month, approximately 89,000 rows)\n",
    "\n",
    "Since we have e-commerce transactions data, the most sensible way to do the split is based on time. So we will use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[df.invoicedate < '2011-10-09']\n",
    "df_val = df[(df.invoicedate >= '2011-10-09') & (df.invoicedate <= '2011-11-09')]\n",
    "df_test = df[df.invoicedate >= '2011-11-09']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will consider the following (very simplified) recommendation scenario:\n",
    "\n",
    "The user enters the website.\n",
    "We present five recommendations.\n",
    "The user assesses the lists, maybe buys some things from there, and then continues shopping as usual.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will consider the following (very simplified) recommendation scenario:\n",
    "\n",
    "The user enters the website.\n",
    "We present five recommendations.\n",
    "The user assesses the lists, maybe buys some things from there, and then continues shopping as usual.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting a baseline, calculate how many of each item was bought, then\n",
    "# take the frequent 5 items and recommend them to all users \n",
    "# (recommendations by popularity)\n",
    "top = df_train.stockcode.value_counts().head(5).index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3527, 3506, 1347, 2730,  180])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top # these are the top 5 product stock codes that got bought\n",
    "    # from the dataset (top 5 products purchased)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_groups = len(df_val.invoiceno.drop_duplicates())\n",
    "base = np.tile(top, num_groups).reshape(-1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3527, 3506, 1347, 2730,  180],\n",
       "       [3527, 3506, 1347, 2730,  180],\n",
       "       [3527, 3506, 1347, 2730,  180],\n",
       "       ...,\n",
       "       [3527, 3506, 1347, 2730,  180],\n",
       "       [3527, 3506, 1347, 2730,  180],\n",
       "       [3527, 3506, 1347, 2730,  180]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See where a transaction finishes, and where the\n",
    "# next one starts\n",
    "def group_indptr(df):\n",
    "    # At each row index, we compare the current index\n",
    "    # with the previous one, and if it is different\n",
    "    # we record the index. We use this using the shift() method\n",
    "    indptr, = np.where(df.invoiceno != df.invoiceno.shift())\n",
    "    indptr = np.append(indptr, len(df)).astype('int32')\n",
    "    return indptr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pointers array for the validation set\n",
    "val_indptr = group_indptr(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import njit\n",
    "\n",
    "'''\n",
    "\n",
    "The logic of this function is straight forward, \n",
    "\n",
    "For each transaction, we check how many items we predicted correctly,\n",
    "which is the 'tp' variable\n",
    "\n",
    "At the end, we divide 'tp' by the total number of predictions, which\n",
    "is the size of the prediction matrix, that the number of transactions\n",
    "times 5 in our case.\n",
    "\n",
    "@njit is a decorator that tells numba to optimize the code, where it \n",
    "analyzes the code using the JIT compiler (just-in-time) to translate the\n",
    "function to native code\n",
    "\n",
    "When the function is compiled, it runs multiple orders of magnitude faster\n",
    "comparable to native code written in C\n",
    "\n",
    "\n",
    "'''\n",
    "@njit \n",
    "def precision(group_indptr, true_items, predicted_items):\n",
    "    tp = 0 # True # of predictions\n",
    "\n",
    "    n, m = predicted_items.shape # total number of predictions our system made\n",
    "\n",
    "    for i in range(n):\n",
    "        group_start = group_indptr[i]\n",
    "        group_end = group_indptr[i + 1]\n",
    "        \n",
    "        # Groups a single transaction that manifested\n",
    "        # in multiple rows in the CSV\n",
    "        group_true_items = true_items[group_start:group_end]\n",
    "        \n",
    "        # Checking precision\n",
    "        for item in group_true_items:\n",
    "            for j in range(m):\n",
    "                if item == predicted_items[i, j]:\n",
    "                    tp = tp + 1\n",
    "                    continue\n",
    "\n",
    "    # return the # of correct predictions / total predictions\n",
    "    return tp / (n * m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0642299794661191"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "Now we will check what the precision of this baseline number is \n",
    "\n",
    "'''\n",
    "\n",
    "val_items = df_val.stockcode.values\n",
    "precision(val_indptr, val_items, base)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Executing this code should produce 0.064. That is, in 6.4% of the cases we made the correct recommendation. This means that the user ended up buying the recommended item only in 6.4% cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use a technique such as matrix factoriazation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2.2: Matrix factorization\n",
    "\n",
    "We will be using Matrix Factorization for our recommendation system, it is powerful, scalable, and is easy to implement and deploy\n",
    "\n",
    "We will optimize (minimize) the cost function by using SVD with a regularization term above.\n",
    "\n",
    "Regularization is used so that the optimization function doesn't overfit our training model to the data, so our weights don't get thrown off by certain data points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2.3: Implicit Feedback Datasets\n",
    "\n",
    "So the thing with collecting data for recommender systems to work well is that we need to first of all, collect a lot of data. This comes in 2 main ways, explicit feedback and implicit feedback.\n",
    "\n",
    "Explicit Feedback is given by the users explicity where a user goes onto a website and we ask how much they would rate a move from 1-5 stars\n",
    "\n",
    "Implicit Feedback has to do with data a system collected that users do not explicitly give by using their browsing history, clicks, page time, etc. etc. Mainly interaction information.\n",
    "\n",
    "Our dataset tells us what the users previously bought, but does not tell us what the users do not like. **We do not know if the usres did not buy an items because they did not like it or just because they did not know the iterm existed**\n",
    "\n",
    "We can luckily still apply matrix factorization to implicit datasets\n",
    "\n",
    "1. Use ALS in implicit library to get a baseline stronger than the previous one, prepare data the way implicit expects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/moebg/miniconda3/lib/python3.6/site-packages/pandas/core/generic.py:4401: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "# Constructing user-item matrix X, translate both\n",
    "# users and items into IDs, so we can map each user to a row of x\n",
    "# and an iterm to a column of X\n",
    "df_train_user = df_train[df_train.customerid != -1].reset_index(drop=True)\n",
    "customers = sorted(set(df_train_user.customerid))\n",
    "customers = {c: i for (i, c) in enumerate(customers)}\n",
    "df_train_user.customerid = df_train_user.customerid.map(customers)\n",
    "\n",
    "# apply same procedure to validation set\n",
    "df_val.customerid = df_val.customerid.apply(lambda c: customers.get(c, -1))\n",
    "\n",
    "# use integer codes to construct the matrix X\n",
    "uid = df_train_user.customerid.values.astype('int32')\n",
    "iid = df_train_user.stockcode.values.astype('int32')\n",
    "ones = np.ones_like(uid, dtype='uint8')\n",
    "\n",
    "X_train = sp.csr_matrix((ones, (uid, iid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
